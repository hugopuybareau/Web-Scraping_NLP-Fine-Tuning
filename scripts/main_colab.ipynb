{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSQoCF-Yud_q"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "259G-eXLud_r"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import requests # HTTP requests\n",
        "from bs4 import BeautifulSoup # Extract HTML content\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuv-XWX9ud_s"
      },
      "source": [
        "# Title scraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8dAhB_bud_s",
        "outputId": "98b6b989-6601-44c1-d322-f3102d684890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: OpenAI pursues public benefit structure to fend off hostile takeovers\n",
            "Link: https://www.ft.com/content/5649b66e-fdb3-46d3-84e0-23e33bdaf363\n",
            "Category: OpenAI\n",
            "----------------------------------------\n",
            "Title: Google DeepMind duo share Nobel chemistry prize with US biochemist\n",
            "Link: https://www.ft.com/content/ba14c3a1-ac8e-42b9-a5ba-9d73cc1fff4c\n",
            "Category: Nobel prizes\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def scrape_tech_news():\n",
        "\n",
        "    url = 'https://www.ft.com/technology'\n",
        "\n",
        "    # HTTP request to scrap page information\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Check response status\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Échec du scraping : {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    # HTML content analysis\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find all the article listed on the page\n",
        "    articles = soup.find_all('div', class_='o-teaser__content')\n",
        "\n",
        "    news = []\n",
        "\n",
        "    for article in articles:\n",
        "        # Title and link extraction\n",
        "        article_heading = article.find('a', class_='js-teaser-heading-link')\n",
        "        title = article_heading.get_text(strip=True) if article_heading else \"No title\"\n",
        "        link = \"https://www.ft.com\" + article_heading['href'] if article_heading else \"No link\"\n",
        "\n",
        "        # Extract article tag to define categories\n",
        "        article_tag = article.find('a', class_='o-teaser__tag')\n",
        "        tag = article_tag['aria-label'] if article_tag else 'No cat'\n",
        "        tag = tag.replace('Category: ', '')\n",
        "\n",
        "        news.append({\n",
        "            'title': title,\n",
        "            'link': link,\n",
        "            'tag': tag,\n",
        "        })\n",
        "\n",
        "    return news\n",
        "\n",
        "ft_news_scraped = scrape_tech_news()\n",
        "\n",
        "# Print\n",
        "for article in ft_news_scraped[0:2]:\n",
        "    print(f\"Title: {article['title']}\")\n",
        "    print(f\"Link: {article['link']}\")\n",
        "    print(f\"Category: {article['tag']}\")\n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8A2PDj9ud_t"
      },
      "source": [
        "# Text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgT1dPp_ud_t",
        "outputId": "869631ac-1d3c-4076-a6f4-0405ece7bb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Pre-trained model to generate text\n",
        "\n",
        "# from openai import OpenAI # I won't use openai cause there is a limit for the requests.\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer # Prompt issue\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "\n",
        "# client = OpenAI(\n",
        "#     api_key = \"xxx\"\n",
        "# )\n",
        "\n",
        "# # T5 model\n",
        "# model_name = 't5-base'\n",
        "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Bart model\n",
        "model_name = \"facebook/bart-large\" # already trained\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZidD7t8ud_t",
        "outputId": "3203d471-abe3-413a-f1d0-bc13dfb65a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: OpenAI pursues public benefit structure to fend off hostile takeovers\n",
            "Link: https://www.ft.com/content/5649b66e-fdb3-46d3-84e0-23e33bdaf363\n",
            "Category: OpenAI\n",
            "Content: Write a tech article on this subject : OpenAI pursues public benefit structure to fend off hostile takeovers.\n",
            "\n",
            " ==================================================================================================== \n",
            "\n",
            "Title: Google DeepMind duo share Nobel chemistry prize with US biochemist\n",
            "Link: https://www.ft.com/content/ba14c3a1-ac8e-42b9-a5ba-9d73cc1fff4c\n",
            "Category: Nobel prizes\n",
            "Content: Write a tech article on this subject : Google DeepMind duo share Nobel chemistry prize with US biochemist.\n",
            "\n",
            " ==================================================================================================== \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generator function\n",
        "\n",
        "def generate_content_from_title(title):\n",
        "    prompt = f\"Write a tech article on this subject : {title}.\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=2000, truncation=True)\n",
        "\n",
        "    outputs = model.generate(inputs.input_ids, max_length=2000, num_beams=4)\n",
        "\n",
        "    # Decrypt generated text\n",
        "    article = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return article\n",
        "\n",
        "\n",
        "for article in ft_news_scraped[0:2]:\n",
        "    title = article['title']\n",
        "    # tag = article['tag']\n",
        "    article['content'] = generate_content_from_title(title)\n",
        "    article['content'] = article['content'].replace('. ', '. \\n') # Output ergonomy\n",
        "\n",
        "# Print\n",
        "for article in ft_news_scraped[0:2]:\n",
        "    print(f\"Title: {article['title']}\")\n",
        "    print(f\"Link: {article['link']}\")\n",
        "    print(f\"Category: {article['tag']}\")\n",
        "    print(f\"Content: {article['content']}\")\n",
        "    print('\\n', \"=\" * 100, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zI9jv_3tud_u"
      },
      "outputs": [],
      "source": [
        "# The Bart model is not self-sufficient.\n",
        "# I will be working on a fine-tuning solution to get better text generations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74p_6XN3ud_u"
      },
      "source": [
        "# Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR5RM3xdud_u"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx-OPsYyvv6Z",
        "outputId": "85b93119-fb80-4b79-ce11-6fa7ccff0bf6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wi6jlhtUud_u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "df = pd.read_csv('articles_cleaned.csv')\n",
        "# df = pd.read_csv('../articles/articles_cleaned.csv')\n",
        "ds = Dataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "c75d80a301524c46b71c73d758671d4d",
            "bde744eab71a49989f59f4c7f64b1f6b",
            "0cb840840d834513b83d20b972457cd7",
            "4283c4613f524f8799d1b47a7fb77dea",
            "763b8acb4a7249b28c5a29a71fb6829d",
            "68d077ddc1094ed78111efaaa567bf3a",
            "a3ae3d1eabfb4dbf8b31810fc9ea8123",
            "69cf2754f0ac4fbcb08e6b69a4ab193a",
            "3ba985b758034cd4868eb6c9880030ba",
            "4f0013ccc1454616b2490d9446189959",
            "e211c0e63f33468698c61605c41cc863"
          ]
        },
        "id": "b2FIytPFud_u",
        "outputId": "4d7fcc44-0fed-4f0d-d35b-56654b394f42"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/17 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c75d80a301524c46b71c73d758671d4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Format the articles' content for the training\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples['title']\n",
        "    targets = examples['full_content']\n",
        "\n",
        "    # Tokenize (This function litterally does the neetcode problem with the tweets and amazon review.)\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Tokenize the contents as labels\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = ds.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRdnItDPud_u"
      },
      "source": [
        "Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ4v9zFIud_u",
        "outputId": "19e07194-0d22-4b46-8393-05edfed59182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens (input_ids):\n",
            "['<s>', 'Reddit', 'Ġis', 'Ġbringing', 'ĠAI', '-', 'powered', ',', 'Ġautomatic', 'Ġtranslation', 'Ġto', 'Ġdozens', 'Ġof', 'Ġnew', 'Ġcountries', 'Ġ-', 'ĠTech', 'Crunch', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "\n",
            "Decoded Input Text:\n",
            "Reddit is bringing AI-powered, automatic translation to dozens of new countries - TechCrunch\n",
            "\n",
            " ==================================================================================================== \n",
            "\n",
            "Tokens (labels):\n",
            "['<s>', 'Reddit', 'Ġis', 'Ġbringing', 'Ġmachine', 'Ġlearning', '-', 'powered', 'Ġtranslations', 'Ġto', 'Ġmore', 'Ġthan', 'Ġ35', 'Ġnew', 'Ġlocal', 'es', 'Ġin', 'ĠEurope', ',', 'ĠAsia', ',', 'Ġand', 'ĠLatin', 'ĠAmerica', 'Ġin', 'Ġa', 'Ġmove', 'Ġdesigned', 'Ġto', 'Ġopen', 'Ġthe', 'Ġlargely', 'ĠEnglish', '-', 'centric', 'Ġsocial', 'Ġnetwork', 'Ġto', 'Ġmore', 'Ġusers', '.', 'Ċ', 'Ċ', 'The', 'Ġservice', 'Ġcomes', 'Ġnearly', 'Ġfive', 'Ġmonths', 'Ġafter', 'ĠReddit', 'Ġfirst', 'Ġintroduced', 'Ġsite', '-', 'wide', 'Ġtranslation', 'Ġfor', 'ĠFrench', 'Ġspeakers', ',', 'Ġthough', 'Ġthe', 'Ġcompany', 'Ġhad', 'Ġpreviously', 'Ġenabled', 'Ġusers', 'Ġto', 'Ġtranslate', 'Ġindividual', 'Ġposts', 'Ġacross', 'Ġseveral', 'Ġlanguages', '.', 'ĠReddit', 'Ġalready', 'Ġallows', 'Ġusers', 'Ġto', 'Ġstip', 'ulate', 'Ġtheir', 'Ġpreferred', 'Ġcontent', 'Ġlanguage', 'Ġfor', 'Ġpost', 'Ġrecommendations', ',', 'Ġas', 'Ġwell', 'Ġas', 'Ġset', 'Ġtheir', 'Ġdisplay', 'Ġlanguage', ',', 'Ġwhich', 'Ġtranslates', 'Ġthe', 'ĠReddit', 'Ġinterface', 'Ġitself', '.', 'Ċ', 'Ċ', 'Today', 'âĢ', 'Ļ', 's', 'Ġannouncement', 'Ġfollows', 'Ġseven', 'Ġmonths', 'Ġafter', 'ĠReddit', 'Ġwent', 'Ġpublic', ',', 'Ġand', 'Ġalthough', 'Ġthe', 'Ġcompany', 'Ġhas', 'Ġsaid', 'Ġits', 'Ġuser', 'Ġbase', 'Ġand', 'Ġad', 'Ġrevenue', 'Ġcontinue', 'Ġto', 'Ġgrow', ',', 'Ġthe', 'Ġmost', 'Ġobvious', 'Ġconduit', 'Ġfor', 'Ġattracting', 'Ġa', 'Ġlarger', 'Ġbase', 'Ġis', 'Ġto', 'Ġmake', 'Ġall', 'Ġits', 'Ġcontent', 'Ġavailable', 'Ġin', 'Ġmore', 'Ġlanguages', '.', 'Ċ', 'Ċ', 'The', 'Ġbig', 'Ġselling', 'Ġpoint', 'Ġof', 'ĠReddit', 'âĢ', 'Ļ', 's', 'Ġnew', 'Ġtranslation', 'Ġfeature', 'Ġis', 'Ġthat', 'Ġusers', 'Ġcan', 'Ġconfigure', 'Ġboth', 'Ġposts', 'Ġand', 'Ġthe', 'Ġcorresponding', 'Ġcomments', 'Ġto', 'Ġauto', '-', 'trans', 'late', 'Ġfrom', 'Ġa', 'Ġcommunity', 'âĢ', 'Ļ', 's', 'Ġoriginal', 'Ġlanguage', 'Ġto', 'Ġthe', 'Ġuser', 'âĢ', 'Ļ', 's', 'Ġown', 'Ġlanguage', 'Ġaccording', 'Ġto', 'Ġtheir', 'ĠReddit', 'Ġsettings', '.', 'ĠThis', 'Ġmeans', 'Ġthat', 'Ġa', 'Ġconversation', 'Ġcan', 'Ġflow', 'Ġin', 'Ġa', 'Ġgiven', 'Ġsubreddit', 'Ġbetween', 'Ġtwo', 'Ġdifferent', 'Ġlanguages', ',', 'Ġand', 'Ġusers', 'Ġwon', 'âĢ', 'Ļ', 't', 'Ġhave', 'Ġto', 'Ġmanually', 'Ġtranslate', 'Ġevery', 'Ġresponse', '.', 'ĠYou', 'Ġcan', 'Ġpost', 'Ġin', 'Ġwhatever', 'Ġlanguage', 'Ġyou', 'Ġwant', ',', 'Ġand', 'Ġas', 'Ġlong', 'Ġas', 'ĠReddit', 'Ġsupports', 'Ġit', ',', 'Ġit', 'Ġwill', 'Ġautomatically', 'Ġbe', 'Ġtranslated', 'Ġinto', 'Ġthe', 'Ġcommunity', 'âĢ', 'Ļ', 's', 'Ġpre', '-', 'set', 'Ġlanguage', '.', 'Ċ', 'Ċ', 'To', 'Ġdo', 'Ġthis', ',', 'Ġusers', 'Ġin', 'Ġsupported', 'Ġlocal', 'es', 'Ġwill', 'Ġsee', 'Ġa', 'Ġnew', 'Ġtranslate', 'Ġicon', 'Ġin', 'Ġtheir', 'Ġmenu', 'Ġthat', 'Ġwill', 'Ġlet', 'Ġthem', 'Ġview', 'Ġcontent', 'Ġin', 'Ġtheir', 'Ġpreferred', 'Ġlanguage', '.', 'Ċ', 'Ċ', 'Posts', 'Ġthat', 'Ġhave', 'Ġbeen', 'Ġtranslated', 'Ġby', 'ĠReddit', 'Ġwill', 'Ġbe', 'Ġlabeled', 'Ġas', 'Ġsuch', ',', 'Ġand', 'Ġusers', 'Ġwill', 'Ġbe', 'Ġable', 'Ġto', 'Ġchoose', 'Ġto', 'Ġview', 'Ġposts', 'Ġin', 'Ġthe', 'Ġoriginal', 'Ġlanguage', 'Ġif', 'Ġthey', 'Ġwish', '.', 'Ċ', 'Ċ', 'Reddit', 'Ġtranslation', 'Ġin', 'Ġaction', 'ĠImage', 'ĠCredits', ':', 'ĠReddit', 'Ċ', 'Ċ', 'Similar', 'Ġto', 'Ġwhat', 'Ġit', 'Ġdid', 'Ġwith', 'Ġtranslating', 'Ġposts', 'Ġin', 'ĠFrench', 'Ġearlier', 'Ġthis', 'Ġyear', ',', 'ĠReddit', 'Ġsaid', 'Ġthat', 'Ġthe', 'Ġcontent', 'Ġwill', 'Ġbe', 'Ġindexed', 'Ġin', 'Ġthe', 'Ġsupported', 'Ġlanguages', 'Ġfor', 'Ġsearch', 'Ġengines', ',', 'Ġmeaning', 'Ġpeople', 'ĠGo', 'og', 'ling', 'Ġfor', 'Ġanswers', 'Ġto', 'Ġquestions', 'Ġin', 'Ġtheir', 'Ġown', 'Ġtongue', 'Ġwill', 'Ġsee', 'Ġresults', 'Ġfrom', 'ĠReddit', ',', 'Ġtoo', '.', 'Ċ', 'Ċ', 'Reddit', 'Ġdoesn', 'âĢ', 'Ļ', 't', 'Ġoutline', 'Ġall', 'Ġthe', 'Ġnew', 'Ġlanguages', 'Ġit', 'Ġwill', 'Ġsupport', ',', 'Ġbut', 'Ġthe', 'Ġtranslation', 'Ġservice', 'Ġis', 'Ġalready', 'Ġavailable', 'Ġin', 'ĠBrazil', 'Ġand', 'ĠSpain', 'Ġas', 'Ġof', 'Ġtoday', ',', 'Ġso', 'Ġone', 'Ġcan', 'Ġassume', 'Ġthat', 'ĠBrazilian', 'ĠPortuguese', 'Ġand', 'ĠSpanish', 'Ġare', 'Ġnow', 'Ġsupported', 'ĠâĢĶ', 'Ġthough', 'Ġpresumably', 'Ġonly', 'Ġin', 'Ġthose', 'Ġcountries', '.', 'Ċ', 'Ċ', 'Reddit', 'Ġadded', 'Ġthat', 'Ġit', 'Ġplans', 'Ġto', 'Ġexpand', 'ĠAI', '-', 'powered', 'Ġtranslations', 'Ġto', 'ĠGermany', ',', 'ĠItaly', ',', 'Ġthe', 'ĠPhilippines', ',', 'Ġand', 'Ġmarkets', 'Ġacross', 'ĠLatin', 'ĠAmerica', 'ĠâĢ', 'ľ', 'in', 'Ġthe', 'Ġcoming', 'Ġweeks', '.', 'âĢ', 'Ŀ', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "\n",
            "Decoded Target Text:\n",
            "Reddit is bringing machine learning-powered translations to more than 35 new locales in Europe, Asia, and Latin America in a move designed to open the largely English-centric social network to more users.\n",
            "\n",
            "The service comes nearly five months after Reddit first introduced site-wide translation for French speakers, though the company had previously enabled users to translate individual posts across several languages. Reddit already allows users to stipulate their preferred content language for post recommendations, as well as set their display language, which translates the Reddit interface itself.\n",
            "\n",
            "Today’s announcement follows seven months after Reddit went public, and although the company has said its user base and ad revenue continue to grow, the most obvious conduit for attracting a larger base is to make all its content available in more languages.\n",
            "\n",
            "The big selling point of Reddit’s new translation feature is that users can configure both posts and the corresponding comments to auto-translate from a community’s original language to the user’s own language according to their Reddit settings. This means that a conversation can flow in a given subreddit between two different languages, and users won’t have to manually translate every response. You can post in whatever language you want, and as long as Reddit supports it, it will automatically be translated into the community’s pre-set language.\n",
            "\n",
            "To do this, users in supported locales will see a new translate icon in their menu that will let them view content in their preferred language.\n",
            "\n",
            "Posts that have been translated by Reddit will be labeled as such, and users will be able to choose to view posts in the original language if they wish.\n",
            "\n",
            "Reddit translation in action Image Credits: Reddit\n",
            "\n",
            "Similar to what it did with translating posts in French earlier this year, Reddit said that the content will be indexed in the supported languages for search engines, meaning people Googling for answers to questions in their own tongue will see results from Reddit, too.\n",
            "\n",
            "Reddit doesn’t outline all the new languages it will support, but the translation service is already available in Brazil and Spain as of today, so one can assume that Brazilian Portuguese and Spanish are now supported — though presumably only in those countries.\n",
            "\n",
            "Reddit added that it plans to expand AI-powered translations to Germany, Italy, the Philippines, and markets across Latin America “in the coming weeks.”\n"
          ]
        }
      ],
      "source": [
        "# Output to check that everything works\n",
        "sample = tokenized_dataset[0]\n",
        "\n",
        "# InputIDs to readable tokens\n",
        "tokens_input = tokenizer.convert_ids_to_tokens(sample['input_ids'])\n",
        "\n",
        "# Print them\n",
        "print(\"Tokens (input_ids):\")\n",
        "print(tokens_input)\n",
        "\n",
        "# Decrypted text\n",
        "decoded_input_text = tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
        "print(\"\\nDecoded Input Text:\")\n",
        "print(decoded_input_text)\n",
        "\n",
        "print('\\n', '=' * 100, '\\n')\n",
        "\n",
        "# Same for the actual content\n",
        "tokens_label = tokenizer.convert_ids_to_tokens(sample['labels'])\n",
        "print(\"Tokens (labels):\")\n",
        "print(tokens_label)\n",
        "decoded_target_text = tokenizer.decode(sample['labels'], skip_special_tokens=True)\n",
        "print(\"\\nDecoded Target Text:\")\n",
        "print(decoded_target_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSwPfS1hud_u"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dCTpWclsud_u"
      },
      "outputs": [],
      "source": [
        "# Datasets building\n",
        "\n",
        "train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = train_test_split['train']\n",
        "test_dataset = train_test_split['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "leyMUB3bud_u",
        "outputId": "1c535484-867c-4b67-ead7-bccafae3f028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 10:37, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>9.854807</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('../models/fine_tuned_bart_1/tokenizer_config.json',\n",
              " '../models/fine_tuned_bart_1/special_tokens_map.json',\n",
              " '../models/fine_tuned_bart_1/vocab.json',\n",
              " '../models/fine_tuned_bart_1/merges.txt',\n",
              " '../models/fine_tuned_bart_1/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "import torch\n",
        "device = torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",     # Compute at each epoch\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,   # If > 1, MPS backend goes out of memory\n",
        "    per_device_eval_batch_size=1,    # If > 1, MPS backend goes out of memory\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    # fp16=True,                      # Uses float numbers coded in 16bits instead of 32bits for lighter memory use\n",
        "    save_total_limit=2,              # Save no more than 2 checkpoints\n",
        "    save_steps=500,                  # Save at 500 steps\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "model.save_pretrained('models/fine_tuned_bart_1')\n",
        "tokenizer.save_pretrained('models/fine_tuned_bart_1')\n",
        "# model.save_pretrained('../models/fine_tuned_bart_1')\n",
        "# tokenizer.save_pretrained('../models/fine_tuned_bart_1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r fine_tuned_bart_1.zip models/fine_tuned_bart_1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygHOXKo0oq2",
        "outputId": "f5cda895-6b31-4a10-f5fb-fa880964f9a0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: models/fine_tuned_bart_1/ (stored 0%)\n",
            "  adding: models/fine_tuned_bart_1/merges.txt (deflated 53%)\n",
            "  adding: models/fine_tuned_bart_1/model.safetensors (deflated 7%)\n",
            "  adding: models/fine_tuned_bart_1/generation_config.json (deflated 47%)\n",
            "  adding: models/fine_tuned_bart_1/config.json (deflated 64%)\n",
            "  adding: models/fine_tuned_bart_1/special_tokens_map.json (deflated 85%)\n",
            "  adding: models/fine_tuned_bart_1/vocab.json (deflated 68%)\n",
            "  adding: models/fine_tuned_bart_1/tokenizer_config.json (deflated 76%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R291qG-B0sP8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "LLM_project_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c75d80a301524c46b71c73d758671d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bde744eab71a49989f59f4c7f64b1f6b",
              "IPY_MODEL_0cb840840d834513b83d20b972457cd7",
              "IPY_MODEL_4283c4613f524f8799d1b47a7fb77dea"
            ],
            "layout": "IPY_MODEL_763b8acb4a7249b28c5a29a71fb6829d"
          }
        },
        "bde744eab71a49989f59f4c7f64b1f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d077ddc1094ed78111efaaa567bf3a",
            "placeholder": "​",
            "style": "IPY_MODEL_a3ae3d1eabfb4dbf8b31810fc9ea8123",
            "value": "Map: 100%"
          }
        },
        "0cb840840d834513b83d20b972457cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69cf2754f0ac4fbcb08e6b69a4ab193a",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ba985b758034cd4868eb6c9880030ba",
            "value": 17
          }
        },
        "4283c4613f524f8799d1b47a7fb77dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f0013ccc1454616b2490d9446189959",
            "placeholder": "​",
            "style": "IPY_MODEL_e211c0e63f33468698c61605c41cc863",
            "value": " 17/17 [00:01&lt;00:00, 14.01 examples/s]"
          }
        },
        "763b8acb4a7249b28c5a29a71fb6829d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d077ddc1094ed78111efaaa567bf3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3ae3d1eabfb4dbf8b31810fc9ea8123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69cf2754f0ac4fbcb08e6b69a4ab193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba985b758034cd4868eb6c9880030ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f0013ccc1454616b2490d9446189959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e211c0e63f33468698c61605c41cc863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}