{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSQoCF-Yud_q"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "259G-eXLud_r"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import requests # HTTP requests\n",
        "from bs4 import BeautifulSoup # Extract HTML content\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuv-XWX9ud_s"
      },
      "source": [
        "# Title scraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8dAhB_bud_s",
        "outputId": "98b6b989-6601-44c1-d322-f3102d684890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: OpenAI pursues public benefit structure to fend off hostile takeovers\n",
            "Link: https://www.ft.com/content/5649b66e-fdb3-46d3-84e0-23e33bdaf363\n",
            "Category: OpenAI\n",
            "----------------------------------------\n",
            "Title: Google DeepMind duo share Nobel chemistry prize with US biochemist\n",
            "Link: https://www.ft.com/content/ba14c3a1-ac8e-42b9-a5ba-9d73cc1fff4c\n",
            "Category: Nobel prizes\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def scrape_tech_news():\n",
        "\n",
        "    url = 'https://www.ft.com/technology'\n",
        "\n",
        "    # HTTP request to scrap page information\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Check response status\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Ã‰chec du scraping : {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    # HTML content analysis\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find all the article listed on the page\n",
        "    articles = soup.find_all('div', class_='o-teaser__content')\n",
        "\n",
        "    news = []\n",
        "\n",
        "    for article in articles:\n",
        "        # Title and link extraction\n",
        "        article_heading = article.find('a', class_='js-teaser-heading-link')\n",
        "        title = article_heading.get_text(strip=True) if article_heading else \"No title\"\n",
        "        link = \"https://www.ft.com\" + article_heading['href'] if article_heading else \"No link\"\n",
        "\n",
        "        # Extract article tag to define categories\n",
        "        article_tag = article.find('a', class_='o-teaser__tag')\n",
        "        tag = article_tag['aria-label'] if article_tag else 'No cat'\n",
        "        tag = tag.replace('Category: ', '')\n",
        "\n",
        "        news.append({\n",
        "            'title': title,\n",
        "            'link': link,\n",
        "            'tag': tag,\n",
        "        })\n",
        "\n",
        "    return news\n",
        "\n",
        "ft_news_scraped = scrape_tech_news()\n",
        "\n",
        "# Print\n",
        "for article in ft_news_scraped[0:2]:\n",
        "    print(f\"Title: {article['title']}\")\n",
        "    print(f\"Link: {article['link']}\")\n",
        "    print(f\"Category: {article['tag']}\")\n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8A2PDj9ud_t"
      },
      "source": [
        "# Text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgT1dPp_ud_t",
        "outputId": "869631ac-1d3c-4076-a6f4-0405ece7bb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Pre-trained model to generate text\n",
        "\n",
        "# from openai import OpenAI # I won't use openai cause there is a limit for the requests.\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer # Prompt issue\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "\n",
        "# client = OpenAI(\n",
        "#     api_key = \"xxx\"\n",
        "# )\n",
        "\n",
        "# # T5 model\n",
        "# model_name = 't5-base'\n",
        "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Bart model\n",
        "model_name = \"facebook/bart-large\" # already trained\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZidD7t8ud_t",
        "outputId": "3203d471-abe3-413a-f1d0-bc13dfb65a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: OpenAI pursues public benefit structure to fend off hostile takeovers\n",
            "Link: https://www.ft.com/content/5649b66e-fdb3-46d3-84e0-23e33bdaf363\n",
            "Category: OpenAI\n",
            "Content: Write a tech article on this subject : OpenAI pursues public benefit structure to fend off hostile takeovers.\n",
            "\n",
            " ==================================================================================================== \n",
            "\n",
            "Title: Google DeepMind duo share Nobel chemistry prize with US biochemist\n",
            "Link: https://www.ft.com/content/ba14c3a1-ac8e-42b9-a5ba-9d73cc1fff4c\n",
            "Category: Nobel prizes\n",
            "Content: Write a tech article on this subject : Google DeepMind duo share Nobel chemistry prize with US biochemist.\n",
            "\n",
            " ==================================================================================================== \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generator function\n",
        "\n",
        "def generate_content_from_title(title):\n",
        "    prompt = f\"Write a tech article on this subject : {title}.\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=2000, truncation=True)\n",
        "\n",
        "    outputs = model.generate(inputs.input_ids, max_length=2000, num_beams=4)\n",
        "\n",
        "    # Decrypt generated text\n",
        "    article = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return article\n",
        "\n",
        "\n",
        "for article in ft_news_scraped[0:2]:\n",
        "    title = article['title']\n",
        "    # tag = article['tag']\n",
        "    article['content'] = generate_content_from_title(title)\n",
        "    article['content'] = article['content'].replace('. ', '. \\n') # Output ergonomy\n",
        "\n",
        "# Print\n",
        "for article in ft_news_scraped[0:2]:\n",
        "    print(f\"Title: {article['title']}\")\n",
        "    print(f\"Link: {article['link']}\")\n",
        "    print(f\"Category: {article['tag']}\")\n",
        "    print(f\"Content: {article['content']}\")\n",
        "    print('\\n', \"=\" * 100, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zI9jv_3tud_u"
      },
      "outputs": [],
      "source": [
        "# The Bart model is not self-sufficient.\n",
        "# I will be working on a fine-tuning solution to get better text generations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74p_6XN3ud_u"
      },
      "source": [
        "# Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR5RM3xdud_u"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx-OPsYyvv6Z",
        "outputId": "85b93119-fb80-4b79-ce11-6fa7ccff0bf6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wi6jlhtUud_u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "df = pd.read_csv('articles_cleaned.csv')\n",
        "# df = pd.read_csv('../articles/articles_cleaned.csv')\n",
        "ds = Dataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "c75d80a301524c46b71c73d758671d4d",
            "bde744eab71a49989f59f4c7f64b1f6b",
            "0cb840840d834513b83d20b972457cd7",
            "4283c4613f524f8799d1b47a7fb77dea",
            "763b8acb4a7249b28c5a29a71fb6829d",
            "68d077ddc1094ed78111efaaa567bf3a",
            "a3ae3d1eabfb4dbf8b31810fc9ea8123",
            "69cf2754f0ac4fbcb08e6b69a4ab193a",
            "3ba985b758034cd4868eb6c9880030ba",
            "4f0013ccc1454616b2490d9446189959",
            "e211c0e63f33468698c61605c41cc863"
          ]
        },
        "id": "b2FIytPFud_u",
        "outputId": "4d7fcc44-0fed-4f0d-d35b-56654b394f42"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/17 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c75d80a301524c46b71c73d758671d4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Format the articles' content for the training\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples['title']\n",
        "    targets = examples['full_content']\n",
        "\n",
        "    # Tokenize (This function litterally does the neetcode problem with the tweets and amazon review.)\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Tokenize the contents as labels\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = ds.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRdnItDPud_u"
      },
      "source": [
        "Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ4v9zFIud_u",
        "outputId": "19e07194-0d22-4b46-8393-05edfed59182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens (input_ids):\n",
            "['<s>', 'Reddit', 'Ä is', 'Ä bringing', 'Ä AI', '-', 'powered', ',', 'Ä automatic', 'Ä translation', 'Ä to', 'Ä dozens', 'Ä of', 'Ä new', 'Ä countries', 'Ä -', 'Ä Tech', 'Crunch', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "\n",
            "Decoded Input Text:\n",
            "Reddit is bringing AI-powered, automatic translation to dozens of new countries - TechCrunch\n",
            "\n",
            " ==================================================================================================== \n",
            "\n",
            "Tokens (labels):\n",
            "['<s>', 'Reddit', 'Ä is', 'Ä bringing', 'Ä machine', 'Ä learning', '-', 'powered', 'Ä translations', 'Ä to', 'Ä more', 'Ä than', 'Ä 35', 'Ä new', 'Ä local', 'es', 'Ä in', 'Ä Europe', ',', 'Ä Asia', ',', 'Ä and', 'Ä Latin', 'Ä America', 'Ä in', 'Ä a', 'Ä move', 'Ä designed', 'Ä to', 'Ä open', 'Ä the', 'Ä largely', 'Ä English', '-', 'centric', 'Ä social', 'Ä network', 'Ä to', 'Ä more', 'Ä users', '.', 'ÄŠ', 'ÄŠ', 'The', 'Ä service', 'Ä comes', 'Ä nearly', 'Ä five', 'Ä months', 'Ä after', 'Ä Reddit', 'Ä first', 'Ä introduced', 'Ä site', '-', 'wide', 'Ä translation', 'Ä for', 'Ä French', 'Ä speakers', ',', 'Ä though', 'Ä the', 'Ä company', 'Ä had', 'Ä previously', 'Ä enabled', 'Ä users', 'Ä to', 'Ä translate', 'Ä individual', 'Ä posts', 'Ä across', 'Ä several', 'Ä languages', '.', 'Ä Reddit', 'Ä already', 'Ä allows', 'Ä users', 'Ä to', 'Ä stip', 'ulate', 'Ä their', 'Ä preferred', 'Ä content', 'Ä language', 'Ä for', 'Ä post', 'Ä recommendations', ',', 'Ä as', 'Ä well', 'Ä as', 'Ä set', 'Ä their', 'Ä display', 'Ä language', ',', 'Ä which', 'Ä translates', 'Ä the', 'Ä Reddit', 'Ä interface', 'Ä itself', '.', 'ÄŠ', 'ÄŠ', 'Today', 'Ã¢Ä¢', 'Ä»', 's', 'Ä announcement', 'Ä follows', 'Ä seven', 'Ä months', 'Ä after', 'Ä Reddit', 'Ä went', 'Ä public', ',', 'Ä and', 'Ä although', 'Ä the', 'Ä company', 'Ä has', 'Ä said', 'Ä its', 'Ä user', 'Ä base', 'Ä and', 'Ä ad', 'Ä revenue', 'Ä continue', 'Ä to', 'Ä grow', ',', 'Ä the', 'Ä most', 'Ä obvious', 'Ä conduit', 'Ä for', 'Ä attracting', 'Ä a', 'Ä larger', 'Ä base', 'Ä is', 'Ä to', 'Ä make', 'Ä all', 'Ä its', 'Ä content', 'Ä available', 'Ä in', 'Ä more', 'Ä languages', '.', 'ÄŠ', 'ÄŠ', 'The', 'Ä big', 'Ä selling', 'Ä point', 'Ä of', 'Ä Reddit', 'Ã¢Ä¢', 'Ä»', 's', 'Ä new', 'Ä translation', 'Ä feature', 'Ä is', 'Ä that', 'Ä users', 'Ä can', 'Ä configure', 'Ä both', 'Ä posts', 'Ä and', 'Ä the', 'Ä corresponding', 'Ä comments', 'Ä to', 'Ä auto', '-', 'trans', 'late', 'Ä from', 'Ä a', 'Ä community', 'Ã¢Ä¢', 'Ä»', 's', 'Ä original', 'Ä language', 'Ä to', 'Ä the', 'Ä user', 'Ã¢Ä¢', 'Ä»', 's', 'Ä own', 'Ä language', 'Ä according', 'Ä to', 'Ä their', 'Ä Reddit', 'Ä settings', '.', 'Ä This', 'Ä means', 'Ä that', 'Ä a', 'Ä conversation', 'Ä can', 'Ä flow', 'Ä in', 'Ä a', 'Ä given', 'Ä subreddit', 'Ä between', 'Ä two', 'Ä different', 'Ä languages', ',', 'Ä and', 'Ä users', 'Ä won', 'Ã¢Ä¢', 'Ä»', 't', 'Ä have', 'Ä to', 'Ä manually', 'Ä translate', 'Ä every', 'Ä response', '.', 'Ä You', 'Ä can', 'Ä post', 'Ä in', 'Ä whatever', 'Ä language', 'Ä you', 'Ä want', ',', 'Ä and', 'Ä as', 'Ä long', 'Ä as', 'Ä Reddit', 'Ä supports', 'Ä it', ',', 'Ä it', 'Ä will', 'Ä automatically', 'Ä be', 'Ä translated', 'Ä into', 'Ä the', 'Ä community', 'Ã¢Ä¢', 'Ä»', 's', 'Ä pre', '-', 'set', 'Ä language', '.', 'ÄŠ', 'ÄŠ', 'To', 'Ä do', 'Ä this', ',', 'Ä users', 'Ä in', 'Ä supported', 'Ä local', 'es', 'Ä will', 'Ä see', 'Ä a', 'Ä new', 'Ä translate', 'Ä icon', 'Ä in', 'Ä their', 'Ä menu', 'Ä that', 'Ä will', 'Ä let', 'Ä them', 'Ä view', 'Ä content', 'Ä in', 'Ä their', 'Ä preferred', 'Ä language', '.', 'ÄŠ', 'ÄŠ', 'Posts', 'Ä that', 'Ä have', 'Ä been', 'Ä translated', 'Ä by', 'Ä Reddit', 'Ä will', 'Ä be', 'Ä labeled', 'Ä as', 'Ä such', ',', 'Ä and', 'Ä users', 'Ä will', 'Ä be', 'Ä able', 'Ä to', 'Ä choose', 'Ä to', 'Ä view', 'Ä posts', 'Ä in', 'Ä the', 'Ä original', 'Ä language', 'Ä if', 'Ä they', 'Ä wish', '.', 'ÄŠ', 'ÄŠ', 'Reddit', 'Ä translation', 'Ä in', 'Ä action', 'Ä Image', 'Ä Credits', ':', 'Ä Reddit', 'ÄŠ', 'ÄŠ', 'Similar', 'Ä to', 'Ä what', 'Ä it', 'Ä did', 'Ä with', 'Ä translating', 'Ä posts', 'Ä in', 'Ä French', 'Ä earlier', 'Ä this', 'Ä year', ',', 'Ä Reddit', 'Ä said', 'Ä that', 'Ä the', 'Ä content', 'Ä will', 'Ä be', 'Ä indexed', 'Ä in', 'Ä the', 'Ä supported', 'Ä languages', 'Ä for', 'Ä search', 'Ä engines', ',', 'Ä meaning', 'Ä people', 'Ä Go', 'og', 'ling', 'Ä for', 'Ä answers', 'Ä to', 'Ä questions', 'Ä in', 'Ä their', 'Ä own', 'Ä tongue', 'Ä will', 'Ä see', 'Ä results', 'Ä from', 'Ä Reddit', ',', 'Ä too', '.', 'ÄŠ', 'ÄŠ', 'Reddit', 'Ä doesn', 'Ã¢Ä¢', 'Ä»', 't', 'Ä outline', 'Ä all', 'Ä the', 'Ä new', 'Ä languages', 'Ä it', 'Ä will', 'Ä support', ',', 'Ä but', 'Ä the', 'Ä translation', 'Ä service', 'Ä is', 'Ä already', 'Ä available', 'Ä in', 'Ä Brazil', 'Ä and', 'Ä Spain', 'Ä as', 'Ä of', 'Ä today', ',', 'Ä so', 'Ä one', 'Ä can', 'Ä assume', 'Ä that', 'Ä Brazilian', 'Ä Portuguese', 'Ä and', 'Ä Spanish', 'Ä are', 'Ä now', 'Ä supported', 'Ä Ã¢Ä¢Ä¶', 'Ä though', 'Ä presumably', 'Ä only', 'Ä in', 'Ä those', 'Ä countries', '.', 'ÄŠ', 'ÄŠ', 'Reddit', 'Ä added', 'Ä that', 'Ä it', 'Ä plans', 'Ä to', 'Ä expand', 'Ä AI', '-', 'powered', 'Ä translations', 'Ä to', 'Ä Germany', ',', 'Ä Italy', ',', 'Ä the', 'Ä Philippines', ',', 'Ä and', 'Ä markets', 'Ä across', 'Ä Latin', 'Ä America', 'Ä Ã¢Ä¢', 'Ä¾', 'in', 'Ä the', 'Ä coming', 'Ä weeks', '.', 'Ã¢Ä¢', 'Ä¿', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "\n",
            "Decoded Target Text:\n",
            "Reddit is bringing machine learning-powered translations to more than 35 new locales in Europe, Asia, and Latin America in a move designed to open the largely English-centric social network to more users.\n",
            "\n",
            "The service comes nearly five months after Reddit first introduced site-wide translation for French speakers, though the company had previously enabled users to translate individual posts across several languages. Reddit already allows users to stipulate their preferred content language for post recommendations, as well as set their display language, which translates the Reddit interface itself.\n",
            "\n",
            "Todayâ€™s announcement follows seven months after Reddit went public, and although the company has said its user base and ad revenue continue to grow, the most obvious conduit for attracting a larger base is to make all its content available in more languages.\n",
            "\n",
            "The big selling point of Redditâ€™s new translation feature is that users can configure both posts and the corresponding comments to auto-translate from a communityâ€™s original language to the userâ€™s own language according to their Reddit settings. This means that a conversation can flow in a given subreddit between two different languages, and users wonâ€™t have to manually translate every response. You can post in whatever language you want, and as long as Reddit supports it, it will automatically be translated into the communityâ€™s pre-set language.\n",
            "\n",
            "To do this, users in supported locales will see a new translate icon in their menu that will let them view content in their preferred language.\n",
            "\n",
            "Posts that have been translated by Reddit will be labeled as such, and users will be able to choose to view posts in the original language if they wish.\n",
            "\n",
            "Reddit translation in action Image Credits: Reddit\n",
            "\n",
            "Similar to what it did with translating posts in French earlier this year, Reddit said that the content will be indexed in the supported languages for search engines, meaning people Googling for answers to questions in their own tongue will see results from Reddit, too.\n",
            "\n",
            "Reddit doesnâ€™t outline all the new languages it will support, but the translation service is already available in Brazil and Spain as of today, so one can assume that Brazilian Portuguese and Spanish are now supported â€” though presumably only in those countries.\n",
            "\n",
            "Reddit added that it plans to expand AI-powered translations to Germany, Italy, the Philippines, and markets across Latin America â€œin the coming weeks.â€\n"
          ]
        }
      ],
      "source": [
        "# Output to check that everything works\n",
        "sample = tokenized_dataset[0]\n",
        "\n",
        "# InputIDs to readable tokens\n",
        "tokens_input = tokenizer.convert_ids_to_tokens(sample['input_ids'])\n",
        "\n",
        "# Print them\n",
        "print(\"Tokens (input_ids):\")\n",
        "print(tokens_input)\n",
        "\n",
        "# Decrypted text\n",
        "decoded_input_text = tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
        "print(\"\\nDecoded Input Text:\")\n",
        "print(decoded_input_text)\n",
        "\n",
        "print('\\n', '=' * 100, '\\n')\n",
        "\n",
        "# Same for the actual content\n",
        "tokens_label = tokenizer.convert_ids_to_tokens(sample['labels'])\n",
        "print(\"Tokens (labels):\")\n",
        "print(tokens_label)\n",
        "decoded_target_text = tokenizer.decode(sample['labels'], skip_special_tokens=True)\n",
        "print(\"\\nDecoded Target Text:\")\n",
        "print(decoded_target_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSwPfS1hud_u"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dCTpWclsud_u"
      },
      "outputs": [],
      "source": [
        "# Datasets building\n",
        "\n",
        "train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = train_test_split['train']\n",
        "test_dataset = train_test_split['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "leyMUB3bud_u",
        "outputId": "1c535484-867c-4b67-ead7-bccafae3f028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 10:37, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>9.854807</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('../models/fine_tuned_bart_1/tokenizer_config.json',\n",
              " '../models/fine_tuned_bart_1/special_tokens_map.json',\n",
              " '../models/fine_tuned_bart_1/vocab.json',\n",
              " '../models/fine_tuned_bart_1/merges.txt',\n",
              " '../models/fine_tuned_bart_1/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "import torch\n",
        "device = torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",     # Compute at each epoch\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,   # If > 1, MPS backend goes out of memory\n",
        "    per_device_eval_batch_size=1,    # If > 1, MPS backend goes out of memory\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    # fp16=True,                      # Uses float numbers coded in 16bits instead of 32bits for lighter memory use\n",
        "    save_total_limit=2,              # Save no more than 2 checkpoints\n",
        "    save_steps=500,                  # Save at 500 steps\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "model.save_pretrained('models/fine_tuned_bart_1')\n",
        "tokenizer.save_pretrained('models/fine_tuned_bart_1')\n",
        "# model.save_pretrained('../models/fine_tuned_bart_1')\n",
        "# tokenizer.save_pretrained('../models/fine_tuned_bart_1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r fine_tuned_bart_1.zip models/fine_tuned_bart_1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygHOXKo0oq2",
        "outputId": "f5cda895-6b31-4a10-f5fb-fa880964f9a0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: models/fine_tuned_bart_1/ (stored 0%)\n",
            "  adding: models/fine_tuned_bart_1/merges.txt (deflated 53%)\n",
            "  adding: models/fine_tuned_bart_1/model.safetensors (deflated 7%)\n",
            "  adding: models/fine_tuned_bart_1/generation_config.json (deflated 47%)\n",
            "  adding: models/fine_tuned_bart_1/config.json (deflated 64%)\n",
            "  adding: models/fine_tuned_bart_1/special_tokens_map.json (deflated 85%)\n",
            "  adding: models/fine_tuned_bart_1/vocab.json (deflated 68%)\n",
            "  adding: models/fine_tuned_bart_1/tokenizer_config.json (deflated 76%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R291qG-B0sP8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "LLM_project_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c75d80a301524c46b71c73d758671d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bde744eab71a49989f59f4c7f64b1f6b",
              "IPY_MODEL_0cb840840d834513b83d20b972457cd7",
              "IPY_MODEL_4283c4613f524f8799d1b47a7fb77dea"
            ],
            "layout": "IPY_MODEL_763b8acb4a7249b28c5a29a71fb6829d"
          }
        },
        "bde744eab71a49989f59f4c7f64b1f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d077ddc1094ed78111efaaa567bf3a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a3ae3d1eabfb4dbf8b31810fc9ea8123",
            "value": "Map:â€‡100%"
          }
        },
        "0cb840840d834513b83d20b972457cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69cf2754f0ac4fbcb08e6b69a4ab193a",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ba985b758034cd4868eb6c9880030ba",
            "value": 17
          }
        },
        "4283c4613f524f8799d1b47a7fb77dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f0013ccc1454616b2490d9446189959",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e211c0e63f33468698c61605c41cc863",
            "value": "â€‡17/17â€‡[00:01&lt;00:00,â€‡14.01â€‡examples/s]"
          }
        },
        "763b8acb4a7249b28c5a29a71fb6829d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d077ddc1094ed78111efaaa567bf3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3ae3d1eabfb4dbf8b31810fc9ea8123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69cf2754f0ac4fbcb08e6b69a4ab193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba985b758034cd4868eb6c9880030ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f0013ccc1454616b2490d9446189959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e211c0e63f33468698c61605c41cc863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}